#+PROPERTY: header-args:jupyter-python  :session aoc-2024 :kernel aoc
#+PROPERTY: header-args    :pandoc t
#+TITLE: 2024 Solutions

* Imports
#+begin_src jupyter-python
# | eval: true
# | output: false
import dataclasses
import functools
import itertools
import os
import re
import sys
from collections import defaultdict, deque, namedtuple
from queue import PriorityQueue

import more_itertools
import numpy as np
import pandas as pd
import scipy

sys.path.insert(1, "..")

import utils

load = utils.year_load(2024)
#+end_src

* [[https://adventofcode.com/2024/day/1][Day 1: Historian Hysteria]]
** Part 1
Load the data, sort the two columns, find the absolute difference between them and sum the result.
#+begin_src jupyter-python
data = np.sort(load(1, "int"), axis=0)
abs(np.diff(data)).sum()
#+end_src

** Part 2
~numpy~ has a handy method to find the unique values in an array, and their counts. Let's use that to make a dictionary of ~value -> count~ pairs for the right list with a default value of zero, and then just look up that value for each element of the left list.
#+begin_src jupyter-python
lookup = defaultdict(int)
lookup.update(
    {value: count for value, count in zip(*np.unique(data[:, 1], return_counts=True))}
)
sum(x * lookup[x] for x in data[:, 0])
#+end_src

* [[https://adventofcode.com/2024/day/2][Day 2: Red-Nosed Reports]]
** Part 1
Nothing too complicated going on here: load the data, and find the difference between successive values. To account for decreasing sequences, multiply by the sign of the first difference and then require that all the differences be greater than one and less than or equal to three.
#+begin_src jupyter-python
data = load(2, "int")


def is_safe(line):
    diff = np.diff(line)
    diff = diff * np.sign(diff[0])
    return int(((diff > 0) & (diff <= 3)).all())


sum(is_safe(line) for line in data)
#+end_src
** Part 2
I spent a bit of time trying to see if there was a neat way of incorporating the "is valid if any one number is deleted" requirement, but I couldn't immediately see it, so I ended up just iterating over all the possible deletions instead.
#+begin_src jupyter-python
total = 0
for line in data:
    for idx in range(len(line)):
        if is_safe(line[:idx] + line[idx + 1 :]):
            total += 1
            break
total
#+end_src
* [[https://adventofcode.com/2024/day/3][Day 3: Mull It Over]]
** Part 1
We get to play with ~regex~! Well, I do -- there might be better ways of tackling this. The format for a valid ~mul~ instruction is quite strict, encoding that as a regex is fairly straightforward. Once we have that, we can use ~re.findall~ to find all the occurrences and extract the integers.
#+begin_src jupyter-python
data = load(3, "raw")
mul = r"mul\((\d{1,3}),(\d{1,3})\)"
sum(int(pair[0]) * int(pair[1]) for pair in re.findall(mul, data))
#+end_src
** Part 2:
I'm pretty happy with my part two, which I managed to do fairly elegantly. We can ignore all the sections immediately after a ~don't()~ instruction by splitting the string on those, and then discarding the start of each substring up to the first ~do()~ instruction. Concatenating all the substrings gives us a clean string with just the segments we are interested in, and we can proceed as before.
#+begin_src jupyter-python
clean = "".join(
    [segment[segment.find("do()") :] for segment in ("do()" + data).split("don't()")]
)
sum(int(pair[0]) * int(pair[1]) for pair in re.findall(mul, clean))
#+end_src
* [[https://adventofcode.com/2024/day/4][Day 4: Ceres Search]]
** Part 1
#+begin_src jupyter-python
data = np.array([[ord(char) for char in line] for line in load(4)])
mask = np.array([ord(char) for char in "XMAS"])


def xmas(chararray):
    return (chararray == mask).all() or (chararray == mask[::-1]).all()


footprints = [np.eye(4), np.fliplr(np.eye(4)), [[1, 1, 1, 1]], [[1], [1], [1], [1]]]

sum(
    scipy.ndimage.generic_filter(data, xmas, footprint=footprint, mode="constant").sum()
    for footprint in footprints
)
#+end_src

** Part 2
#+begin_src jupyter-python
masks = ["MMASS", "SMASM", "MSAMS", "SSAMM"]
encoded_masks = [np.array([ord(char) for char in mask]) for mask in masks]
footprint = [[1, 0, 1], [0, 1, 0], [1, 0, 1]]
def x_mas(chararray):
    for mask in encoded_masks:
        if (chararray == mask).all():
            return 1
    return 0
scipy.ndimage.generic_filter(data, x_mas, footprint=footprint, mode="constant").sum()
#+end_src

* [[https://adventofcode.com/2024/day/5][Day 5: Print Queue]]
This problem screams topological sort, so that's what I'm going with. For part one, to account for the case where multiple orderings of a line might obey the rules, the we'll use a function to check whether the line order is compatible with the order given in the update.

That's not too tricky: just iterate through the update, and for each item in the update

1. Check that it's not blocked by any later items
2. Remove any blocks that the current item is placing on later items, since it's successfully been placed

If we get through the whole update without finding a blocked item, then the order is valid and we should include it in the sum.   

** Part 1
#+begin_src jupyter-python
rules, updates = [x.split("\n") for x in load(5, "raw").split("\n\n")]
updates = [[int(x) for x in line.split(",")] for line in updates]
ancestors = defaultdict(list)
descendents = defaultdict(list)
for rule in rules:
    first, last = map(int, rule.split("|"))
    ancestors[last].append(first)
    descendents[first].append(last)


def restriction(rules, keys):
    return {key: [x for x in rules[key] if x in keys] for key in keys}


def is_sorted(keys):
    keys = keys.copy()
    pre = restriction(ancestors, keys)
    post = restriction(descendents, keys)
    while keys:
        current = keys.pop(0)
        if pre[current]:
            return False
        del pre[current]
        for item in post[current]:
            pre[item] = [x for x in pre[item] if x != current]
    return True


sum(update[len(update) // 2] for update in updates if is_sorted(update))
#+end_src

** Part 2
For part 2 we'll actually implement the topological sort. I vaguely remembered how to do this, but it took a couple of iterations to get right.

The idea is that we start by scanning the rules dictionary for items which are eligible for immediate placement, and remove them from the list.

We then iteratively place these items, and for each item we place, we remove any blocks that they might have placed on later items. That might mean that new items are eligible for placement, and in this way we iterate through the entire list and output an order compatible with the rules.
#+begin_src jupyter-python
def topological_sort(keys):
    pre = restriction(ancestors, keys)
    post = restriction(descendents, keys)
    result = []
    to_delete = [key for key in pre if not pre[key]]
    for key in to_delete:
        del pre[key]
    while to_delete:
        n = to_delete.pop()
        result.append(n)
        for item in post[n]:
            pre[item] = [x for x in pre[item] if x != n]
            if not pre[item]:
                to_delete.append(item)
                del pre[item]
    return result


sum(topological_sort(line)[len(line) // 2] for line in updates if not is_sorted(line))
#+end_src

* [[https://adventofcode.com/2024/day/6][Day 6: Guard Gallivant]]

** Part 1
#+begin_src jupyter-python
data = np.array(
    [
        [0 if char == "." else 1 if char == "#" else 2 for char in line]
        for line in load(6)
    ]
)
dy, dx = [-1, 0]
y, x = [int(x) for x in np.array(np.where(data == 2)).ravel()]
ymax, xmax = data.shape

def is_valid(y, x):
    return y > 0 and x > 0 and y < ymax - 1 and x < xmax - 1

path = [(y, x, dy, dx)]
while is_valid(y, x):
    while data[y + dy, x + dx] % 2:
        dy, dx = [dy, dx] @ np.array([[0, -1], [1, 0]])
    y, x = y + dy, x + dx
    path.append((y, x, dy, dx))
len(set((x[0], x[1]) for x in path))
#+end_src

** Part 2
For part two, we should realise that only obstacles placed on the path have any chance of affecting what the guard does, so the relevant search space is significantly smaller than "every vacant square on the board". There's also no need to start the guard from the initial position for every new obstacle; we can just start her on the path right in front of the new obstacle. Similarly, if she ever gets back on her original path before the obstacle, we know she must be in a loop, so we can start with a visited set that covers the whole pwth right up to the new obstruction.
#+begin_src jupyter-python
attempted_positions = set([path[0][:2]])
total = 0
for idx in range(1, len(path)):
    obstacle_y, obstacle_x, _, _ = path[idx]
    if (obstacle_y, obstacle_x) in attempted_positions:
        continue
    y, x, dy, dx = path[idx - 1]
    data[obstacle_y, obstacle_x] = 1
    seen = set(path[:idx - 1])
    while is_valid(y, x):
        seen.add((y, x, dy, dx))
        while data[y + dy, x + dx] % 2:
            dy, dx = [dy, dx] @ np.array([[0, -1], [1, 0]])
        while is_valid(y, x) and data[y + dy, x + dx] % 2 == 0:
            y, x = y + dy, x + dx
        if (y, x, dy, dx) in seen:
            total += 1
            break
    attempted_positions.add((obstacle_y, obstacle_x))
    data[obstacle_y, obstacle_x] = 0
total
#+end_src

