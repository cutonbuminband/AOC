#+PROPERTY: header-args:jupyter-python  :session aoc-2022 :kernel aoc
#+PROPERTY: header-args    :pandoc t

* Imports
#+begin_src jupyter-python
  import pandas as pd
  import numpy as np
  from collections import defaultdict
  from pathlib import Path
  import functools
  import itertools
  import more_itertools
  import re
  import collections

  datadir = Path("data/2022")
  import utils

  load = utils.year_load(2022)
#+end_src

* Day 1
[[https://adventofcode.com/2022/day/1][Calorie Counting]]
** Part 1
The Elves take turns writing down the number of Calories contained by the various meals, snacks, rations, etc. that they've brought with them, one item per line. Each Elf separates their own inventory from the previous Elf's inventory (if any) by a blank line.

Find the Elf carrying the most Calories. How many total Calories is that Elf carrying?

#+begin_src jupyter-python
  elves = [x.split("\n") for x in load(1, "raw").split("\n\n")]
  max([sum([int(y) for y in x if y]) for x in elves])
#+end_src

** Part 2
By the time you calculate the answer to the Elves' question, they've already realized that the Elf carrying the most Calories of food might eventually run out of snacks.

To avoid this unacceptable situation, the Elves would instead like to know the total Calories carried by the top three Elves carrying the most Calories. That way, even if one of those Elves runs out of snacks, they still have two backups.

#+begin_src jupyter-python
  sum(sorted([sum([int(y) for y in x if y]) for x in elves])[-3:])
#+end_src

* Day 2:
[[https://adventofcode.com/2022/day/2][Rock Paper Scissors]]

** Part 1
#+begin_src jupyter-python
  lines = [
      [ord(x) - ord("A"), ord(y) - ord("X")]
      for x, y in map(str.split, open(datadir / "2.txt").readlines())
  ]
  sum([line[1] + 1 + 3 * ((line[1] - line[0] + 1) % 3) for line in lines])
#+end_src

** Part 2
#+begin_src jupyter-python
  sum([(line[1] + line[0] - 1) % 3 + 1 + 3 * line[1] for line in lines])
#+end_src

* Day 3:
[[https://adventofcode.com/2022/day/3][Rucksack Reorganization]]
** Part 1
#+begin_src jupyter-python
  total = 0
  lines = list(map(str.strip, open(datadir / "3.txt", encoding="utf8")))
  for l in lines:
      letter = set(l[: len(l) // 2]).intersection(set(l[len(l) // 2 :])).pop()
      total += ord(letter.upper()) - ord("A") + 1 + 26 * letter.isupper()
  total
#+end_src

** Part 2
#+begin_src jupyter-python
  total = 0
  for chunk in more_itertools.chunked(lines, 3):
      letter = functools.reduce(lambda x, y: set(x').intersection(set(y)), chunk).pop()
      total += ord(letter.upper()) - ord("A") + 1 + 26 * letter.isupper()
  total
#+end_src

* Day 4
[[https://adventofcode.com/2022/day/4][Camp Cleanup]]
** Part 1
#+begin_src jupyter-python
  assignments = [x.strip() for x in open(datadir / "4.txt", encoding="utf8").readlines()]
  regex = re.compile("\d+")
  assignments = map(lambda x: [int(y) for y in re.findall(regex, x)], assignments)
  assignments = [sorted([a[:2], a[2:]]) for a in assignments]
  sum((a[1] >= b[1] or a[0] == b[0]) for a, b in assignments)
#+end_src

** Part 2
#+begin_src jupyter-python
  sum((a[1] >= b[0] or a[0] == b[0]) for a, b in assignments)
#+end_src

* Day 5
[[https://adventofcode.com/2022/day/5][Supply Stacks]]

** Part 1
#+begin_src jupyter-python
  lines = [line.strip() for line in open(datadir / "5.txt").readlines()]
  numbers = [re.findall("\d+", line) for line in lines]
  split = np.argmax([len(x) for x in numbers])
  instructions = [[int(y) for y in x] for x in numbers[split + 1 :] if x]
  initial_state = list(itertools.zip_longest(*lines[:split]))

  letters = [re.findall("[A-Z]", "".join(column)) for column in initial_state]
  p1 = [x[::-1] for x in letters.copy() if x]
  for n, source, dest in instructions:
      for i in range(n):
          p1[dest - 1].append(p1[source - 1].pop())
  "".join(x[-1] if x else " " for x in p1)
#+end_src

** Part 2
#+begin_src jupyter-python
  p2 = [x[::-1] for x in letters.copy() if x]
  for n, source, dest in instructions:
      p2[dest - 1] += p2[source - 1][-n:]
      p2[source - 1] = p2[source - 1][:-n]
  "".join(x[-1] if x else " " for x in p2)
#+end_src

* Day 6
[[https://adventofcode.com/2022/day/6][Tuning Trouble]]
** Part 1
#+begin_src jupyter-python
  data = open(datadir / "6.txt").readline()


  def find_marker(n):
      for i in range(len(data) - n + 1):
          if len(set(list(data[i : i + n]))) == n:
              return i + n


  find_marker(4)
#+end_src

** Part 2
#+begin_src jupyter-python
  find_marker(14)
#+end_src

* Day 7
[[https://adventofcode.com/2022/day/7][No Space Left On Device]]
** Part 1
This requires a bit of tedious bookkeeping, but is otherwise straightforward.

Keeping track of full names is necessary, since "/foo/baz" and "/bar/baz" refer to two different directories.

The following code has a bug where it will show incorrect totals if the contents of the same directory are described more than once. Luckily, that doesn't seem to ever happen.
#+begin_src jupyter-python
  lines = [line.strip() for line in open(datadir / "7.txt").readlines()]
  directory = {"/": {"children": [], "parent": None, "weights": []}}


  def get_fullname(name, parent):
      return f"{parent if parent != '/' else ''}/{name}"


  def add_directory(name, parent, directory):
      fullname = get_fullname(name, parent)
      directory[fullname] = {"children": [], "parent": parent, "weights": []}
      directory[parent]["children"].append(fullname)


  for idx, line in enumerate(lines):
      if "$ cd" in line:
          target = line.split()[-1]
          if target == "..":
              cwd = directory[cwd]["parent"]
          elif target == "/":
              cwd = "/"
          else:
              cwd = get_fullname(target, cwd)
      if line[0] != "$":
          metadata, name = line.split()
          if metadata == "dir":
              if name not in directory:
                  add_directory(name, cwd, directory)
          else:
              directory[cwd]["weights"].append(int(metadata))
  weights = {}


  def calculate_weights(node):
      if node not in weights:
          weights[node] = sum(directory[node]["weights"]) + sum(
              calculate_weights(node) for node in directory[node]["children"]
          )
      return weights[node]


  calculate_weights("/")
  sum(weight for weight in weights.values() if weight <= 100_000)
#+end_src

** Part 2
The weight of every directory has been stored in the weight dict, so finding the smallest one that's greater than a given threshold is trivial
#+begin_src jupyter-python
  to_free = weights["/"] - 40_000_000
  min(weight for weight in weights.values() if weight >= to_free)
#+end_src

* Day 8
[[https://adventofcode.com/2022/day/8][Treetop Tree House]]
** Part 1
It really feels like there should be a slick array-based solution to this: calculate the cumulative max from each of the four directions, take the minimum of those four and compare with our array. But it doesn't seem like numpy has easy functionality for calculating the cumulative max.

A bit off digging reveals the very useful ufunc `accumulate`, which does exactly what we need. Then it's just a question of getting it to work in the four directions. Either we change the axis and direction of operation, or (as here) we transform the data from one orientation to another, do the accumulation, and transform back at the end.
#+begin_src jupyter-python
  data = np.array([[int(char) for char in line.strip()] for line in load(8)])
  masks = []
  for i in range(4):
      transformed = np.rot90(data, i)
      mask = np.roll(np.maximum.accumulate(transformed), 1, axis=0)
      mask[0] = -1
      masks.append(np.rot90(mask, 4 - i))
  mask = np.min(masks, axis=0)
  (data > mask).sum()
#+end_src

** Part 2
The conceptual approach for this is similar - find a way of calculating the score in one direction, then transform the data to use that operation for the other directions.

There are a couple of gotchas:

- The elves' sightlines are blocked by trees of the same height, not just by trees of greater height. If we want to leverage `maximum` as an indicator, we need to decrease the value of the tree under consideration by one, since otherwise there's no way of distinguishing between a, a - 1 (not blocked) and a, a (blocked).
- The elves can see the tree that they're being blocked by. If we try to account for this by just adding one to all the sightlines, we'll get a bug when they can see all the way to the edge. Instead, we pretend that they can always see the last tree in the forest
#+begin_src jupyter-python
  def scenic_score(data):
      def one_row(i):
          """How many trees can be seen looking down from row i"""
          current = data.copy()
          current[i] = current[i] - 1
          mask = np.maximum.accumulate(np.roll(current, -i, axis=0)) <= current[i]
          mask[-i - 1] = True
          return mask[1 : len(data) - i].sum(axis=0)

      return np.array([one_row(i) for i in range(len(data))])


  scenic_scores = []
  for i in range(4):
      scenic_scores.append(np.rot90(scenic_score(np.rot90(data, i)), 4 - i))
  np.product(scenic_scores, axis=0).max()
#+end_src

** Bonus
The grid here invites plotting. One thing we can plot is the shortest tree which would be visible at each location
#+begin_src jupyter-python
  import matplotlib.pyplot as plt

  plt.imshow(mask + 1)
  plt.xticks([]), plt.yticks([])
  plt.colorbar()
  plt.title("The shortest visible tree at each location")
  plt.savefig("graphs/2022-08.png", bbox_inches="tight")
#+end_src

That gives the following plot

[[graphs/2022-08.png]]

We can see how at the edges of the forest shorter trees are visible, but towards the center they've all been shadowed by taller trees.

* Day 9
[[https://adventofcode.com/2022/day/9][Rope Bridge]]
** Part 1
#+begin_src jupyter-python
  base = {2: 1, 2 + 1j: 1 + 1j, 2 + 2j: 1 + 1j, 1 + 2j: 1 + 1j}
  deltas = {k * 1j**i: v * 1j**i for k, v in base.items() for i in range(4)}
  directions = {"R": 1, "L": -1, "U": 1j, "D": -1j}
  instructions = [x.split() for x in open(datadir / "9.txt").readlines()]


  def tail_moves(rope_length):
      seen = []
      rope = [0] * rope_length
      for direction, count in instructions:
          for _ in range(int(count)):
              rope[0] += directions[direction]
              for i in range(1, len(rope)):
                  rope[i] += (
                      deltas[rope[i - 1] - rope[i]]
                      if abs(rope[i - 1] - rope[i]) >= 2
                      else 0
                  )
              seen.append(rope[-1])
      return seen


  len(set(tail_moves(2)))
#+end_src

** Part 2
#+begin_src jupyter-python
  len(set(tail_moves(10)))
#+end_src

* Day 10
[[https://adventofcode.com/2022/day/10][Cathode-Ray Tube]]

** Part 1
#+begin_src jupyter-python
  instructions = load(10)
  deltas = [
      int(element) if element[-1].isdigit() else 0
      for line in instructions
      for element in line.strip().split()
  ]


  def run(f, result):
      for cycle, x in enumerate(np.cumsum([1] + deltas)):
          result += f(x, cycle + 1)
      return result


  run(lambda x, y: x * y if y % 40 == 20 else 0, 0)
#+end_src

** Part 2
#+begin_src jupyter-python
  def draw_sprite(sprite_position, cycle):
      return "█" if abs(sprite_position - ((cycle - 1) % 40)) <= 1 else " "


  print(*[run(draw_sprite, "")[40 * i : 40 * (i + 1)] for i in range(6)], sep="\n")
#+end_src

* Day 11
[[https://adventofcode.com/2022/day/11][Monkey in the Middle]]
** Part 1
#+begin_src jupyter-python
  data = open(datadir / "11.txt").read()
  monkeys = data.split("\n\n")


  class Monkey:
      def __init__(self, update, test):
          self.update = update
          self.factor = test[0]
          self.target = lambda x: test[1] if x % self.factor == 0 else test[2]


  monkeys = []
  initial_items = []
  for monkey in data.split("\n\n"):
      lines = [line for line in monkey.split("\n") if line]
      update = eval("lambda old: " + lines[2].split(" = ")[1])
      digits = [[int(x) for x in re.findall("\d+", line)] for line in lines]
      monkeys.append(Monkey(update, [x[0] for x in digits[-3:]]))
      initial_items.append(digits[1])


  def run(rounds, function):
      examined = [0] * len(monkeys)
      for monkey, items in zip(monkeys, initial_items):
          monkey.items = items.copy()
      for _ in range(rounds):
          for idx, monkey in enumerate(monkeys):
              examined[idx] += len(monkey.items)
              for i in range(len(monkey.items)):
                  item = function((monkey.update(monkey.items.pop())))
                  monkeys[monkey.target(item)].items.append(item)
      return examined


  np.product(sorted(run(20, lambda x: x // 3))[-2:])
#+end_src

** Part 2
#+begin_src jupyter-python
  common_multiple = np.product([x.factor for x in monkeys])
  np.product(sorted(run(10000, lambda x: x % common_multiple))[-2:])
#+end_src

* Day 12
[[https://adventofcode.com/2022/day/12][Hill Climbing Algorithm]]
** Part 1
#+begin_src jupyter-python
  data = [list(x.strip()) for x in open(datadir / "12.txt").readlines()]
  elevations = np.array([[ord(char) - ord("a") for char in line] for line in data])
  source = tuple(x[0] for x in np.where(elevations == ord("S") - ord("a")))
  target = tuple(x[0] for x in np.where(elevations == ord("E") - ord("a")))
  elevations[source] = 0
  elevations[target] = 25

  xmax, ymax = elevations.shape


  def grid_neighbors(x, y):
      candidates = [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]
      return [c for c in candidates if 0 <= c[0] < xmax and 0 <= c[1] < ymax]


  def find_neighbors(x, y):
      return [n for n in grid_neighbors(x, y) if elevations[n] - elevations[x, y] <= 1]


  def navigate(source, neighbor_func, stop_condition):
      active = collections.deque([(0, source)])
      seen = set()
      while active:
          steps, current = active.popleft()
          if stop_condition(current):
              return steps
          if current in seen:
              continue
          seen.add(current)
          for neighbor in neighbor_func(*current):
              active.append((steps + 1, neighbor))
      return np.inf


  navigate(source, find_neighbors, lambda x: x == target)
#+end_src

** Part 2
#+begin_src jupyter-python
  def reversed_neighbors(x, y):
      return [n for n in grid_neighbors(x, y) if elevations[x, y] - elevations[n] <= 1]


  navigate(target, reversed_neighbors, lambda x: elevations[x] == 0)
#+end_src

* Day 13
[[https://adventofcode.com/2022/day/13][Distress Signal]]
** Part 1
#+begin_src jupyter-python
  import ast


  def compare(left, right):
      if isinstance(left, int) and isinstance(right, int):
          return (left > right) + (left >= right)
      if isinstance(left, int):
          return compare([left], right)
      if isinstance(right, int):
          return compare(left, [right])
      if not left and not right:
          return 1
      if not left:
          return 0
      if not right:
          return 2
      val = compare(left[0], right[0])
      return val if (val == 0 or val == 2) else compare(left[1:], right[1:])


  total = 0
  s = open(datadir / "13.txt").read()[:-1]
  for idx, (left, right) in enumerate(map(lambda x: x.split("\n"), s.split("\n\n"))):
      val = compare(ast.literal_eval(left), ast.literal_eval(right))
      if val == 0:
          total += idx + 1
  total
#+end_src

** Part 2
#+begin_src jupyter-python
  dividers = [[2]], [[6]]
  packets = [
      ast.literal_eval(packet) for pair in s.split("\n\n") for packet in pair.split("\n")
  ]
  positions = [
      sum(compare(divider, packet) == 2 for packet in packets) for divider in dividers
  ]
  (positions[0] + 1) * (positions[1] + 2)
#+end_src

* Day 14
* Day 15
[[https://adventofcode.com/2022/day/15][Beacon Exclusion Zone]]
** Part 1
#+begin_src jupyter-python
  digits = re.compile(r"-?\d+")
  data = open(datadir / "15.txt").read()
  values = [int(x) for x in re.findall(digits, data)]


  def combine_two_intervals(i1, i2):
      i1, i2 = sorted([i1, i2])
      if i2[0] <= i1[1]:
          return i1[0], max(i1[1], i2[1])
      return False


  def combine_n_intervals(intervals):
      active = intervals.copy()
      result = []
      while active:
          current = active.pop()
          for index, previous in enumerate(result):
              new_interval = combine_two_intervals(current, previous)
              if new_interval:
                  del result[index]
                  active.append(new_interval)
                  break
          else:
              result.append(current)
      return result


  y_target = 2000000
  fixes = set()
  intervals = []
  for x, y, u, v in more_itertools.chunked(values, 4):
      r = abs(x - u) + abs(y - v)
      if v == y_target:
          fixes.add(u)
      available = r - abs(y - y_target)
      if available >= 0:
          interval = x - available, x + available + 1
          intervals += [interval]
  intervals = combine_n_intervals(intervals)
  sum(x[1] - x[0] for x in intervals) - len(fixes)
#+end_src

* Day 16
** Part 1
We should start by loading the data, and trying to visualize the graph
#+begin_src jupyter-python
  import sknetwork
  adjacency = {}
  pressures = {}
  for line in open(datadir / "16.txt"):
      pressure = int(re.findall(r"\d+", line)[0])
      left, right = line.split(";")
      node = left.split()[1]
      neighbors = re.sub(".*valves? (.*)", r"\1", right[:-1]).split(",")
      adjacency[node] = neighbors
      pressures[node] = pressure
  graph = sknetwork.data.from_adjacency_list(adjacency, weighted=False)
  
  from sknetwork.embedding.force_atlas import ForceAtlas
  from IPython.display import SVG
  forceatlas2 = ForceAtlas()
  embedding = forceatlas2.fit_transform(graph.adjacency)
  image = sknetwork.visualization.svg_graph(graph.adjacency, embedding, names=graph.names)
  SVG(image)
#+end_src
Looks pretty cool!
#+begin_src jupyter-python
  def optimal_choice(open_valves, score, position, visited, time):
	  if ticks == 0:
		  return score
	  neighbors = adjacency[position]
	  moves = []
	  if position not in open_valves:
		  new_score = score + (time - 1) * pressures[position]
		  moves += [(open_valves + [position], new_score, position, visited, time - 1)]
	  for neighbor in filter(lambda x: x not in visited, neighbors):
		  moves += [(open_valves, neighor, score, visited + [neighbor], time - 1)]
#+end_src

* Day 18
[[https://adventofcode.com/2022/day/18][Boiling Boulders]]
** Part 1
Idea: find all neighboring boxes by finding the union of the shifts along each of i,j,k,-i,-j,-k and subtracting the original shape. A given box might neighbor the original shape in up to six places, so to account for that I can take all the neighbors, shift them againalong each of the axes, and for each shift, count how many boxes now overlap the original shape.
#+begin_src jupyter-python
  data = load(18, "np")


  def to_set(arr):
      return set(tuple(x) for x in arr)


  def inflate(data):
      if isinstance(data, set):
          data = np.array(list(data))
      return to_set(np.vstack([row + data for row in deltas])) - occupied


  occupied = to_set(data)
  deltas = (np.tile(np.eye(3, dtype=int), 2) * np.repeat((1, -1), 3)).T
  nb = inflate(data)
  arr = np.array(list(nb))
  sum([len(to_set(arr + delta) & occupied) for delta in deltas])
#+end_src

** Part 2
For part 2, once we have identified which of the neighboring boxes represent external neighbors (i.e. are connected to the outside world), we can do exactly the same thing. The tricky thing is then to make this identification. Under the assumption that the droplet is connected, so that every box in the droplet is reachable from every other via a series of face, edge or corner moves, then every point the outside boundary is face-connected to every other after at most two inflations. I can then use a union find data structure to merge all the connected groups together, and the outside group is then the largest of all of these
#+begin_src jupyter-python
  from scipy.cluster.hierarchy import DisjointSet

  points = inflate(data)
  for i in range(2):
      points = inflate(points)

  disjoint_set = DisjointSet(points)
  for x in points:
      comparisons = x + np.eye(3, dtype=int)
      for comparison in comparisons:
          if (y := tuple(comparison)) in disjoint_set:
              disjoint_set.merge(x, y)
  max_s = 0
  for subset in disjoint_set.subsets():
      if len(subset) > max_s:
          max_s = len(subset)
          s = subset
  arr = np.array(list(s & nb))
  sum([len(to_set(arr + delta) & occupied) for delta in deltas])
#+end_src
