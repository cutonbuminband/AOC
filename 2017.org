#+PROPERTY: header-args:jupyter-python  :session aoc-2017 :kernel aoc
#+PROPERTY: header-args    :pandoc t

* Imports
#+begin_src jupyter-python
  import pandas as pd
  import numpy as np
  from collections import defaultdict
  from pathlib import Path
  import functools
  import itertools
  import collections
  import re
  import more_itertools
  datadir = Path("data/2017")
#+end_src

* Day 1
[[https://adventofcode.com/2017/day/1][Inverse Captcha]]
** Part 1
#+begin_src jupyter-python
  data = np.array([int(x) for x in open(datadir / "1.txt").readline().strip()], dtype=int)
  data[np.where(data == np.roll(data, 1))].sum()
#+end_src

** Part 2
#+begin_src jupyter-python
  data[np.where(data == np.roll(data, len(data) // 2))].sum()
#+end_src

* Day 2
[[https://adventofcode.com/2017/day/2][Corruption Checksum]]
** Part 1
#+begin_src jupyter-python
  data = [sorted(map(lambda x: int(x), x.split()))
          for x in open(datadir / '2.txt').readlines()]
  sum(a[-1] - a[0] for a in data)
#+end_src

** Part 2
#+begin_src jupyter-python
  total = 0
  for line in data:
      for idx, value in enumerate(line):
          for j in range(idx + 1, len(line)):
              total += line[j] // value if line[j] % value == 0 else 0
  total
#+end_src

* Day 3
[[https://adventofcode.com/2017/day/3][Spiral Memory]]
** Part 1
#+begin_src jupyter-python
  puzzle_input = 368078
  completed_squares = (int(np.sqrt(puzzle_input) - 1) // 2 * 2) + 1
  remainder = (puzzle_input - completed_squares ** 2) % (completed_squares + 1)
  (completed_squares // 2 + 1) + abs((completed_squares // 2) + 1 - remainder)
#+end_src

** Part 2
#+begin_src jupyter-python
  coord, current_side, side_length, remainder = 0, 0, 0, 0
  spiral = defaultdict(int)
  spiral[coord] = 1
  direction = 1
  while True:
      if remainder == side_length:
          if current_side % 4 == 0:
              coord = coord + direction - 1j * direction
              side_length += 2
          direction = 1j * direction
          coord = coord + direction
          current_side += 1
          remainder = 1
      else:
          coord = coord + direction
          remainder += 1
      tmp = 0
      for x, y in itertools.product([-1, 0, 1], [-1j, 0, 1j]):
          if not x and not y: continue
          target = coord + x + y
          tmp += spiral[target]
      if tmp > puzzle_input:
          break
      spiral[coord] = tmp
  tmp
#+end_src

* Day 4
[[https://adventofcode.com/2017/day/4][High-Entropy Passphrases]]
** Part 1
A new system policy has been put in place that requires all accounts to use a passphrase instead of simply a password. A passphrase consists of a series of words (lowercase letters) separated by spaces.

To ensure security, a valid passphrase must contain no duplicate words.
#+begin_src jupyter-python
  lines = [x.split() for x in open(datadir / "4.txt").readlines()]
  sum(len(l) == len(set(l)) for l in lines)
#+end_src

** Part 2
For added security, yet another system policy has been put in place. Now, a valid passphrase must contain no two words that are anagrams of each other.
#+begin_src jupyter-python
  sum(len(l) == len(set([''.join(sorted(w)) for w in l])) for l in lines)
#+end_src

* Day 5
[[https://adventofcode.com/2017/day/5][A Maze of Twisty Trampolines, All Alike]]
** Part 1
#+begin_src jupyter-python
  instructions = np.loadtxt(datadir / "5.txt", dtype=int)
  ip, count = 0, 0
  while ip >= 0 and ip < len(instructions):
      instructions[ip] += 1
      ip += instructions[ip] - 1
      count += 1
  count

#+end_src

** Part 2
#+begin_src jupyter-python
  instructions = np.loadtxt(datadir / "5.txt", dtype=int)
  ip, count = 0, 0
  while ip >= 0 and ip < len(instructions):
      instruction = instructions[ip]
      instructions[ip] += 1 if instruction < 3 else -1
      ip += instruction
      count += 1
  count
#+end_src

* Day 6
[[https://adventofcode.com/2017/day/6][Memory Reallocation]]
** Part 1
#+begin_src jupyter-python
  data = np.array([0, 5, 10, 0, 11, 14, 13, 4, 11, 8, 8, 7, 1, 4, 12, 11])
  l = len(data)
  seen = {}
  i = 0
  def step(data):
      idx, maxval = data.argmax(), data.max()
      data[idx] = 0
      delta = np.ones(len(data), dtype=int) * (maxval // l)
      delta[:maxval % l] += 1
      data += np.roll(delta, idx + 1)
      return data

  while tuple(data) not in seen:
      seen[tuple(data)] = i
      data = step(data)
      i += 1
  i

#+end_src

I was getting the wrong answer for this for the longest time until I realised I'd left off a "0" at the start of my input when I copied it over.

** Part 2
This was made trivial by tracking when a given configuration was seen.
#+begin_src jupyter-python
  i - seen[(tuple(data))]
#+end_src

* Day 7
[[https://adventofcode.com/2017/day/7][Recursive Circus]]
** Part 1
#+begin_src jupyter-python
  data = map(str.strip, open(datadir / "7.txt").readlines())
  tree = {}
  for line in data:
      name = line.split(" ")[0]
      children  = line.split(" -> ")[1].split(", ") if " -> " in line else []
      weight = int(re.findall("\d+", line)[0])
      tree[name] = {"weight": weight, "children": children}
  parents = {}
  for node in tree:
      for child in tree[node]["children"]:
          parents[child] = node
  node = (set(tree.keys()) - set(parents.keys())).pop()
  node
#+end_src

** Part 2
#+begin_src jupyter-python
  def weight(node):
    return tree[node]["weight"] + sum(map(weight, tree[node]["children"]))

  def is_balanced(node):
    return (not tree[node]["children"] or
            len(set(map(weight, tree[node]["children"]))) == 1)

  while not is_balanced(node):
    weights = [weight(x) for x in tree[node]["children"]]
    counts = collections.Counter(weights)
    wrong_weight = min(counts, key=counts.get)
    node = tree[node]["children"][weights.index(wrong_weight)]

  delta = max(counts, key=counts.get) - wrong_weight
  tree[node]["weight"] + delta
#+end_src

* Day 8
[[https://adventofcode.com/2017/day/8][I Heard You Like Registers]]
** Part 1
#+begin_src jupyter-python
  import operator as op
  registers = defaultdict(int)
  instructions = [x.strip().split() for x in open(datadir / "8.txt").readlines()]
  ops = {"<": op.lt, "<=": op.le, "==": op.eq, ">=": op.ge, ">": op.gt, "!=": op.ne}
  signs = {"dec": -1, "inc": 1}
  for target, sign, inc_amount, _, comparator, comparison, cmp_value in instructions:
      if ops[comparison](registers[comparator], int(cmp_value)):
          registers[target] += signs[sign] * int(inc_amount)
  max(registers.values())
#+end_src

** Part 2
#+begin_src jupyter-python
  maxval = 0
  registers = defaultdict(int)
  for target, sign, inc_amount, _, comparator, comparison, cmp_value in instructions:
      if ops[comparison](registers[comparator], int(cmp_value)):
          registers[target] += signs[sign] * int(inc_amount)
      current_max = max(registers.values())
      if current_max > maxval:
          maxval = current_max
  maxval
#+end_src

* Day 9
** Part 1
#+begin_src jupyter-python
def canonical_form(sequence):
    count = 0
    replacements = {'{': '[', ',': ',', '}': ']'}
    mode = 'group'
    skip = False
    result = ''
    for char in sequence:
        if skip:
            skip = False
        elif char == '!':
            skip = True
        elif mode == 'group' and char == '<':
            mode = 'garbage'
        elif mode == 'garbage' and char == '>':
            mode = 'group'
        elif mode == 'garbage':
            count += 1
        elif mode == 'group':
            if char == '}':
                result += replacements[char]
            if char == '{':
                result += replacements[char]
    return result, count

data = open(datadir / '9.txt').readline().strip()
data, count = canonical_form(data)
total, counter = 0, 0
for char in data:
    if char == "[":
        counter += 1
    else:
        total += counter
        counter -= 1
total
#+end_src

** Part 2
#+begin_src jupyter-python
count
#+end_src

* Day 10
[[https://adventofcode.com/2017/day/10][Knot Hash]]
** Part 1
#+begin_src jupyter-python
  data = "165,1,255,31,87,52,24,113,0,91,148,254,158,2,73,153"
  lengths = [int(length) for length in data.split(",")]
  def knot_hash1(lengths):
      knots = collections.deque(range(256))
      total = 0
      for idx, length in enumerate(lengths):
          new = collections.deque([knots.popleft() for _ in range(length)])
          new.reverse()
          knots = knots + new
          knots.rotate(-idx)
          total += length + idx
      knots.rotate(total)
      return knots
  knots = knot_hash1(lengths)
  knots.popleft() * knots.popleft()
#+end_src

** Part 2
#+begin_src jupyter-python
  def knot_hash64(s):
      numbers = [ord(x) for x in s] + [17, 31, 73, 47, 23]
      lengths = itertools.chain.from_iterable(itertools.repeat(numbers, 64))
      knots = list(knot_hash1(lengths))
      digits = [functools.reduce(lambda x, y: x ^ y, knots[16*i: 16*(i+1)]) for i in range(16)]
      return   ''.join(['{:0>2x}'.format(x) for x in digits])
  knot_hash64(data)

#+end_src

* Day 11
[[https://adventofcode.com/2017/day/11][Hex Ed]]

** Part 1
To describe the hexgrid we'll use two basis vectors: x1, directed southeast, and x2, directed due north. All the other directions can be found as linear combinations of these, and the final position in this basis is just the sum of all the moves. Now, any move of the form (k, 1), with k in [-1, 0, 1] only takes one step, so the number of steps needed to reach the final position is just the value of whichever of the two basis vectors we have more of
#+begin_src jupyter-python
  data = open(datadir / "11.txt").read().strip().split(",")
  coordinates = {"se": np.array((1, 0)),
                 "s": np.array((0, -1)),
                 "sw": np.array((-1, -1)),
                 "nw": np.array((-1, 0)),
                 "n": np.array((0, 1)),
                 "ne": np.array((1, 1))}
  moves = np.array([coordinates[x] for x in data])
  max(abs(moves.sum(axis=0)))
#+end_src

** Part 2
For part 2, instead of finding just the sum of the moves, we look at the running total, and ask what the greatest value of any of the coefficients is at any point in the path.
#+begin_src jupyter-python
  abs(moves.cumsum(axis=0)).max()
#+end_src

* Day 12
[[https://adventofcode.com/2017/day/12][Digital Plumber]]

** Part 1
#+begin_src jupyter-python
  regex = "(-?\d+)"
  lines = open(datadir / "12.txt").readlines()
  data = [[int(number) for number in re.findall(regex, line)] for line in lines]
  graph = {line[0]: line[1:] for line in data}
  def find_group(seed):
      queue = set([seed])
      visited = set()
      while queue:
          current = queue.pop()
          visited.add(current)
          for neighbor in graph[current]:
              if neighbor not in visited:
                  queue.add(neighbor)
      return visited
  len(find_group(0))
#+end_src

** Part 2
#+begin_src jupyter-python
  i = 0
  while graph:
      seed = list(graph.keys())[0]
      visited = find_group(seed)
      for key in visited:
          del graph[key]
      i += 1
  i
#+end_src

* Day 13
[[https://adventofcode.com/2017/day/13][Packet Scanners]]
** Part 1
The only slightly tricky thing here is that we have to convert a depth to a cycle length. In each cycle, a scanner of depth d moves down (d - 1) steps, and then back up (d - 1) steps, so the cycle length is 2 * d - 2.
#+begin_src jupyter-python
  data = [list(map(int, line.strip().split(": "))) for line in open(datadir / "13.txt").readlines()]
  sum(map(lambda x: 0 if (x[0] % (x[1] * 2 - 2)) else x[0] * x[1], data))
#+end_src
** Part 2
So, this is another application of the chinese remainder theorem, after a bit of massaging. We have multiple scanners with the same depth at different positions; each such scanner invalidates on congruence class of the integers mod cycle length.

In my input, the depths were almost coprime in the sense that there was one of the scanner depths that divided all the others, and apart from that, the depths were either coprime, or divided one another exactly.

The depths that divide one another exactly can be handled by unfolding the restriction of the smaller number to its higher multiples, and then removing the smaller number from consideration. After that, we can find what numbers would be valid for each depth.

For most of these, there was only one such modulus. Taking all the ones for which that's the case we can use the chinese remainder theorem to solve that system of congruences, and then manually move to higher congruences to satisfy the remaining scanners.
#+begin_src jupyter-python
  import math
  from utils import crt
  scanners = defaultdict(list)
  for position, depth in data:
      scanners[2 * depth - 2].append((- position) % (2 * depth - 2))
      scanners[2 * depth - 2].sort()
  seen = []
  for s1, s2 in itertools.combinations(scanners.keys(), 2):
      s2, s1 = sorted([s1, s2])
      if (s1 % s2) == 0:
          seen.append(s2)
          offsets = list(range(0, s1, s2))
          new_restrictions = list(map(sum, list(itertools.product(offsets, scanners[s2]))))
          restrictions = sorted(set(new_restrictions + scanners[s1]))
          scanners[s1] = restrictions
  for key in set(seen):
      del scanners[key]
  valid = {}
  for scanner in scanners:
      valid[scanner] = sorted(set(range(scanner)) - set(scanners[scanner]))
  g = math.gcd(*(list(valid.keys()) + [element for numbers in valid.values() for element in numbers]))
  congruences = []
  remainder = {}
  for modulus in valid:
      if len(valid[modulus]) == 1:
          congruences.append((int(modulus / g), int( valid[modulus][0]/ g)))
      else:
          remainder[int(modulus / g)] = [int(x / g) for x in valid[modulus] ]
  N = np.product([x[0] for x in congruences])
  x = crt(congruences) - N
  while True:
      x += N
      for v in remainder:
          if (x % v) not in remainder[v]:
              break
      else:
          break
  g * x
#+end_src

* Day 14
[[https://adventofcode.com/2017/day/14][Disk Defragmentation]]
** Part 1
#+begin_src jupyter-python
  prefix = open(datadir / "14.txt").read().strip() + "-"
  hashes = [knot_hash64(prefix + str(i)) for i in range(128)]
  bitstrings = [f"{int(h, 16):0128b}" for h in hashes]
  sum(x.count("1") for x in bitstrings)
#+end_src
** Part 2
#+begin_src jupyter-python
  field = np.array([[ord(x) - ord("0") for x in b] for b in bitstrings])
  graph = defaultdict(list)
  for i, j in itertools.product(range(128), range(128)):
      neighbors = [(i, j+1), (i + 1, j)]
      neighbors = [(x, y) for x, y in neighbors if (x < 128 and y < 128)]
      if not field[i, j]:
          continue
      for neighbor in neighbors:
          if field[neighbor]:
              graph[(i, j)].append(neighbor)
              graph[neighbor].append((i, j))
  count = field.sum() - len(graph)  # singletons
  while graph:
      queue = collections.deque([list(graph.keys())[0]])
      visited = set()
      while queue:
          current = queue.pop()
          visited.add(current)
          for node in graph[current]:
              if node not in visited:
                  queue.append(node)
      for node in visited:
          del graph[node]
      count += 1
  count
#+end_src
