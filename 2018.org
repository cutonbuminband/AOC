#+PROPERTY: header-args:jupyter-python  :session aoc-2018 :kernel aoc
#+PROPERTY: header-args    :pandoc t

* Imports
#+begin_src jupyter-python
  import pandas as pd
  import numpy as np
  from collections import defaultdict, deque
  from pathlib import Path
  import functools
  import itertools
  import more_itertools
  import re
  import scipy
  import utils
  load = utils.year_load(2018)
#+end_src

* Day 1
[[https://adventofcode.com/2018/day/1][Chronal Calibration]]
** Part 1
#+begin_src jupyter-python
  data = load(1, "np")
  data.sum()
#+end_src


** Part 2
#+begin_src jupyter-python
  i = 0
  value = 0
  seen = {}
  while True:
      if value in seen:
          break
      seen[value] = 1
      value += data[i % len(data)]
      i += 1
  value
#+end_src

* Day 2
[[https://adventofcode.com/2018/day/2][Inventory Managment System]]
** Part 1
#+begin_src jupyter-python
  lines = [np.array([ord(y) for y in x.strip()]) for x in load(2)]
  twos = sum([2 in np.unique(list(line), return_counts=True)[1] for line in lines])
  twos * sum([3 in np.unique(list(line), return_counts=True)[1] for line in lines])
#+end_src

** Part 2
#+begin_src jupyter-python
  for s1 in lines:
      for s2 in lines:
          if len(s2) != len(s1): continue
          if (s2 - s1 != 0).sum() == 1:
              result = ''.join(chr(x) for x in s1[np.where(s1 == s2)])
              break
      else:
          continue
      break
result
#+end_src

* Day 3
[[https://adventofcode.com/2018/day/3][No Matter How You Slice It]]
** Part 1
#+begin_src jupyter-python
  import re
  num = re.compile(r"\d+")
  data = np.array([[int(x) for x in re.findall(num, line)] for line in load(3)])
  field = np.zeros([1000, 1000])
  for pid, x, y, w, h in data:
      field[x:x+w, y:y+h] += 1
  (field > 1).sum()
#+end_src

** Part 2
#+begin_src jupyter-python
  for pid, x, y, w, h in data:
      if (field[x:x+w, y:y+h] == 1).all():
          break
  pid
#+end_src

* Day 4
[[https://adventofcode.com/2018/day/4][Repose Record]]
** Part 1
#+begin_src jupyter-python
  from time import strptime
  events = [event[1:].strip().split("] ") for event in load(4)]
  date_format = "%Y-%m-%d %H:%M"
  events = sorted(events, key = lambda event : strptime(event[0], date_format))
  guards = {}
  while events:
      event = events.pop(0)
      if "Guard" in event[1]:
          active_guard = event[1][7:-13]
          if active_guard not in guards:
              guards[active_guard] = np.zeros(60)
          continue
      end = events.pop(0)
      guards[active_guard][int(event[0][-2:]):int(end[0][-2:])] += 1

  sleepiest_guard = sorted(guards.keys(), key = lambda x: - guards[x].sum())[0]
  int(sleepiest_guard) * guards[sleepiest_guard].argmax()
#+end_src

** Part 2
#+begin_src jupyter-python
  sleepiest_guard = sorted(guards.keys(), key = lambda x: - max(guards[x]))[0]
  int(sleepiest_guard) * guards[sleepiest_guard].argmax()
#+end_src

* Day 5
[[https://adventofcode.com/2018/day/5][Alchemical Reduction]]
** Part 1
#+begin_src jupyter-python
  import string
  s = load(5)[0].strip()

  def reduce(s):
      l = len(s)
      for char in string.ascii_lowercase:
          s = s.replace(f"{char + char.swapcase()}", "")
          s = s.replace(f"{char.swapcase() + char}", "")
      return l if l == len(s) else reduce(s)
  reduce(s)
#+end_src

** Part 2
#+begin_src jupyter-python
  min(reduce(s.replace(c, "").replace(c.upper(), "")) for c in string.ascii_lowercase)
#+end_src

* Day 6
[[https://adventofcode.com/2018/day/6][Chronal Coordinates]]

** Part 1
The numbers involved are small enough that brute force is a viable approach. It's ugly, but it works. The question is basically asking for the voronoi diagram of the initial points using the L1 metric, but I'm too slow to see an efficient way of calculating that. The approach would have to be something like determining the boundary line between each pair of points, and then intersecting all of those half planes to get the voronoi cell.
#+begin_src jupyter-python
  data = load(6)
  coordinates = np.array([list(map(int, re.findall("\d+", line))) for line in data])
  xmax, ymax = coordinates.max(axis=0)
  board = np.zeros([xmax, ymax], dtype=int)
  for x, y in itertools.product(range(xmax), range(ymax)):
      distances = (np.abs(coordinates - np.array([x, y]))).sum(axis=1)
      values, counts = np.unique(distances, return_counts=True)
      board[x, y] = distances.argmin() if counts[0] == 1 else -1
  infinite = functools.reduce(lambda x, y: set(x) | set(y), [board[0], board[:, 0], board[-1], board[:, -1]])
  max([(board == seed).sum() if seed not in infinite else 0 for seed in range(len(coordinates))])
#+end_src

** Part 2
#+begin_src jupyter-python
  board = np.zeros([xmax, ymax], dtype=int)
  for x,y in itertools.product(range(xmax), range(ymax)):
      board[x, y] = (np.abs(coordinates - np.array([x, y]))).sum()

  (board < 10000).sum()
#+end_src

** Bonus
I haven't figured out the cleanest way of solving part 1, but here's an approach that's slightly better than brute force. We can basically flood fill the grid, starting with the seed locations given in the input, and then expanding one step at a time. That way we end up considering the effect of at most four (and usually only one or two) seeds on each location, and we avoid having to calculate the distance from the point to every single seed.
#+begin_src jupyter-python
  import matplotlib.pyplot as plt
  board = np.zeros([xmax + 1, ymax + 1], dtype=int)
  def expand_one(cells, idx, to_paint):
      new_cells = []
      for neighbor in get_neighbors(cells):
          if board[neighbor] == 0:
              if neighbor in to_paint:
                  del to_paint[neighbor]
                  board[neighbor] = -1
              else:
                  to_paint[neighbor] = idx + 1
                  new_cells.append(neighbor)

      return new_cells

  def get_neighbors(cells):
      neighbors = []
      for x, y in cells:
          candidates = [(x - 1, y), (x + 1, y), (x, y - 1), (x, y + 1)]
          neighbors += [(x,y) for x,y in candidates if (0 <= x <= xmax) and (0 <= y <= ymax)]
      return set(neighbors)
#+end_src

We can animate the process of expanding each seed

#+begin_src jupyter-python
  to_paint = {tuple(x): idx + 1 for idx, x in enumerate(coordinates)}
  system = [[x] for x in to_paint.keys()]
  boards = []
  while to_paint:
      for key in to_paint:
          board[key] = to_paint[key]
      to_paint = {}
      for idx, cells in enumerate(system):
          system[idx] = expand_one(cells, idx, to_paint)
      image = board.astype(float).copy()
      image[image == 0] = np.nan
      boards.append(image)

  import matplotlib.animation as animation

  s = 3.0
  fig = plt.figure(figsize=(s, s*ymax/xmax))
  l = len(boards)
  i=0
  im = plt.imshow(boards[0], animated=True, cmap="inferno")
  plt.xticks([])
  plt.yticks([])
  def updatefig(*args):
      global i
      if i < len(boards) - 1:
          i += 1
      else:
          i=0
      im.set_array(boards[i])
      return im,
  a = animation.FuncAnimation(fig, updatefig,  blit=True, frames=len(boards))
  a.save('graphs/2018-06.gif', fps=30)
#+end_src

That gives this pretty cool plot

[[https://github.com/cutonbuminband/AOC/blob/main/graphs/2018-06.gif]]

* Day 7
[[https://adventofcode.com/2018/day/7][The Sum of Its Parts]]
** Part 1
#+begin_src jupyter-python
  constraints = {}
  lines = load(7)
  for tokens in map(str.split, lines):
      parent, child = tokens[1], tokens[-3]
      if parent not in constraints:
          constraints[parent] = ['', '']
      if child not in constraints:
          constraints[child] = ['', '']
      constraints[parent][0] += child
      constraints[child][1] += parent
  executed = ''
  available = []

  def pop_node(node, ordering):
      for child in ordering[node][0]:
          idx = ordering[child][1].index(node)
          ordering[child] = [ordering[child][0], ordering[child][1][:idx] + ordering[child][1][idx + 1:]]
      del ordering[node]      

  part1 = constraints.copy()
  while part1:
      available = sorted(set(available + [key for key in part1 if not part1[key][1]]))
      current = available.pop(0)
      executed += current
      pop_node(current, part1)

  executed

#+end_src

** Part 2
#+begin_src jupyter-python
  active = []
  n_workers = 5
  part2 = constraints.copy()
  time = -1
  while part2:
      new_active = []
      for key, count in active:
          if count:
              new_active += [[key, count - 1]]
          else:
              pop_node(key, part2)
      active = new_active
      available = sorted(set(key for key in part2 if not part2[key][1]) - set(x[0] for x in active))
      while available and len(active) < n_workers:
          key = available.pop(0)
          active += [[key, ord(key) - ord('A') + 60]]
      time += 1
  time
#+end_src

* Day 8
[[https://adventofcode.com/2018/day/8][Memory Maneuver]]
** Part 1
#+begin_src jupyter-python
  data = load(8, "int")[0]
  def parse(tree_list):
      result = {"children": []}
      n_children, n_metadata = tree_list[:2]
      tree_list = tree_list[2:]
      for _ in range(n_children):
          tree_list, child = parse(tree_list)
          result["children"] += [child]
      result["metadata"] = tree_list[:n_metadata]
      return tree_list[n_metadata:], result

  def weigh(tree):
      if not tree['children']:
          return sum(tree["metadata"])
      return sum(tree["metadata"]) + sum(map(weigh, tree['children']))

  tree = parse(data)[1]
  weigh(tree)
#+end_src

** Part 2
#+begin_src jupyter-python
  def value(node):
      children = node['children']
      if not children:
          return sum(node["metadata"])
      return sum(value(children[idx - 1]) for idx in node["metadata"]
                 if idx <= len(children))
  value(tree)

#+end_src

* Day 9
[[https://adventofcode.com/2018/day/9][Marble Mania]]
** Part 1
#+begin_src jupyter-python
  n_players = 419
  n_marbles = 72164

  def run(n_players, n_marbles):
      scores = defaultdict(int)
      circle = deque([0])
      for marble in range(1, n_marbles + 1):
          if marble % 23 == 0:
              circle.rotate(7)
              scores[marble % n_players] += marble + circle.pop()
              circle.rotate(-1)
          else:
              circle.rotate(-1)
              circle.append(marble)
      return max(scores.values())
  run(n_players, n_marbles)
#+end_src

** Part 2
#+begin_src jupyter-python
  run(n_players, n_marbles * 100)
#+end_src

* Day 10
[[https://adventofcode.com/2018/day/10][The Stars Align]]
** Part 1
#+begin_src jupyter-python
  array = np.array(load(10, "int"))
  positions = array[:, :2].copy()
  velocities = array[:, 2:]
  bounding_box = np.product(positions.max(axis=0) - positions.min(axis=0))
  old_bounding_box = np.inf
  while bounding_box < old_bounding_box:
      positions += velocities
      old_bounding_box = bounding_box
      bounding_box = np.product(positions.max(axis=0) - positions.min(axis=0))
  positions -= velocities
  board = np.zeros(positions.max(axis=0) - positions.min(axis=0) + 1)
  board[(positions[:, 0] - positions[:, 0].min(), positions[:, 1] - positions[:, 1].min())] = 1
  print('\n'.join([''.join('█' if char else ' ' for char in line) for line in board.T]))
#+end_src

** Part 2
#+begin_src jupyter-python
  int(((positions[0] - array[0, :2]) / velocities[0])[0])
#+end_src

* Day 11
[[https://adventofcode.com/2018/day/11][Chronal Charge]]
** Part 1

#+begin_src jupyter-python
  import scipy
  s = 8772
  board = np.zeros((300, 300), dtype=int)
  for row, col in itertools.product(range(300), range(300)):
      score = ((row + 1 + 10)  * (col + 1) + s) * (row + 1 + 10)
      board[row, col] = (score // 100) % 10
  board -= 5
  best = 0
  for row, col in itertools.product(range(300 - 2), range(300 - 2)):
      total = board[row: row+3, col:col+3].sum()
      if total > best:
          best = total
          result = row + 1, col + 1
  print(",".join(str(x) for x in result))
#+end_src

** Part 2
Brute force over all sizes is slow, but works
#+begin_src jupyter-python
  best = 0
  for i in range(3, 301):
      for row, col in itertools.product(range(301 - i), range(301 - i)):
          total = board[row:row+i, col:col+i].sum()
          if total > best:
              best = total
              result = row + 1, col + 1, i
  print(",".join(str(x) for x in result))
#+end_src

* Day 12
[[https://adventofcode.com/2018/day/12][Subterranean Sustainability]]

** Part 1
#+begin_src jupyter-python
  data = load(12)
  lookup = {".": 0, "#": 1}
  generations = 20
  initial_state = [lookup[char] for char in data[0] if char in lookup]
  state = np.pad(initial_state, generations)
  rules = [line.strip().split(' => ') for line in data[2:]]
  alive = np.array([[lookup[x] for x in rule[0]] for rule in rules if lookup[rule[1]] == 1])
  def update(cell_neighbors):
      return 1 * (not abs(np.array(alive) - cell_neighbors).sum(axis=1).min())

  states = [state.copy()]
  for i in range(generations):
      state = scipy.ndimage.generic_filter(state, update, footprint=np.ones(5), mode='constant')
      states.append(state.copy())
  indices = np.arange(state.shape[0]) - generations
  (indices * state).sum()
#+end_src

** Part 2
Simulating the 50 billion generations is impossible, so something cleverer is needed. My first attempt was to see how the total number of plants changed as the generations progressed, and I noticed that after comparatively gew generations the number was constant. Looking at how the pattern of plants changed after that period made extrapolation to 50 billion generations easy. An off-by-one and an off-by-a-factor-of-ten error later, and the problem was solved.
#+begin_src jupyter-python
  generations = 150
  state = np.pad(initial_state, generations)
  states = [state.copy()]
  for i in range(1, generations):
      new_state = scipy.ndimage.generic_filter(state, update, footprint=np.ones(5), mode='constant')
      states.append(new_state.copy())
      if (new_state == np.roll(state, 1)).all():
          break
      state = new_state
  (((np.arange(new_state.shape[0]) - generations) + (50_000_000_000 - i))*new_state).sum()
#+end_src

* Day 13

** Part 1
[[https://adventofcode.com/2018/day/13][Mine Cart Madness]]
#+begin_src jupyter-python
  characters = r" |-/\+><v^"
  cart_labels = {">": ("-", 1), "<": ("-", -1), "v": ("|", -1j), "^": ("|", 1j)}
  data = load(13)
  graph = {}
  carts = []
  carts_part2 = []
  for y, line in enumerate(data):
      for x, char in enumerate(line.strip("\n")):
          position = x - 1j * y
          if char in cart_labels:
              char, direction = cart_labels[char]
              carts.append([position, direction, itertools.cycle([1j, 1, -1j])])
              carts_part2.append([position, direction, itertools.cycle([1j, 1, -1j])])
          graph[position] = characters.index(char)
  i = 0
  while True:
      for cart in carts:
          new_position = cart[0] + cart[1]
          if new_position in [x[0] for x in carts]:
              result = int(new_position.real), -int(new_position.imag)
              break
          cart[0] = new_position
          tile = graph[new_position]
          if tile == 3:
              cart[1] = cart[1].imag + 1j * cart[1].real
          elif tile == 4:
              cart[1] = -(cart[1].imag + 1j * cart[1].real)
          elif tile == 5:
              cart[1] = cart[1] * next(cart[2])
      else:
          i += 1
          continue
      break
  print(result)
#+end_src

** Part 2
#+begin_src jupyter-python
  carts = carts_part2
  carts.sort(key = lambda x: (-x[0].imag, x[0].real))
  while len(carts) > 1:
      is_crashed = [False] * len(carts)
      for idx, cart in enumerate(carts):
          if is_crashed[idx]:
              continue
          new_position = cart[0] + cart[1]
          crashes = [i for i, cart2 in enumerate(carts)
                     if new_position == cart2[0] and not is_crashed[i]]
          for crash in crashes:
              is_crashed[idx] = True
              is_crashed[crash] = True
              continue
          cart[0] = new_position
          tile = graph[new_position]
          if tile == 3:
              cart[1] = cart[1].imag + 1j * cart[1].real
          elif tile == 4:
              cart[1] = -(cart[1].imag + 1j * cart[1].real)
          elif tile == 5:
              cart[1] = cart[1] * next(cart[2])
      carts = [cart for (crash, cart) in zip(is_crashed, carts) if not crash]
      carts.sort(key = lambda x: (-x[0].imag, x[0].real))
  print(int(carts[0][0].real),int(-carts[0][0].imag),sep=",")
#+end_src

* Day 14
[[https://adventofcode.com/2018/day/14][Chocolate Charts]]
** Part 1
#+begin_src jupyter-python
  def solve(n):
      e1, e2 = 0, 1
      recipes = [3, 7]
      while len(recipes) < n + 10:
          v1, v2 = recipes[e1], recipes[e2]
          tens, units = divmod(v1 + v2, 10)
          recipes += [tens, units] if tens else [units]
          l = len(recipes)
          e1, e2 = (e1 + v1 + 1) % l, (e2 + v2 + 1) % l
      # print(recipes)
      return functools.reduce(lambda x, y: 10*x + y, recipes[n: n + 10])
  solve(157901)

#+end_src

** Part 2
#+begin_src jupyter-python
  def solve(n):
      seq = [int(x) for x in str(n)]
      s = len(seq)
      e1, e2 = 0, 1
      recipes = [3, 7]
      while recipes[-s:] != seq and recipes[-s - 1:-1] != seq:
          v1, v2 = recipes[e1], recipes[e2]
          tens, units = divmod(v1 + v2, 10)
          recipes += [tens, units] if tens else [units]
          l = len(recipes)
          e1, e2 = (e1 + v1 + 1) % l, (e2 + v2 + 1) % l
      delta = 0 if recipes[-s:] == seq else 1
      return l - s - delta
  solve("157901")

#+end_src

* Day 16
[[https://adventofcode.com/2018/day/16][Chronal Classification]]
** Part 1
This is fairly straightforward. We have seven different operations, with two or three different addressing modes for each. We'll start by building a dictionary of each operation, and then one of the valid addressing modes for each operation. From that, we can get a set of all the valid tuples of (operation, addressing mode 1, addressing mode 2).

We can then scan through the header lines of the input, and for each (before, command, after) triple, we can loop over the valid tuples, and check which ones convert before to after.
#+begin_src jupyter-python
  from more_itertools import chunked
  registers = [0, 0, 0, 0]
  ops = {
      "add": lambda a, b: a + b,
      "mul": lambda a, b: a * b,
      "ban": lambda a, b: a & b,
      "bor": lambda a, b: a | b,
      "set": lambda a, b: a,
      "gt": lambda a, b: int(a > b),
      "eq": lambda a, b: int(a == b),
  }

  # 1 is register, 0 is immediate
  valid_modes = defaultdict(lambda: [(1, 0), (1, 1)])
  valid_modes["set"] = [(0, 0), (1, 0)]
  valid_modes["gt"] = [(0, 1), (1, 0), (1, 1)]
  valid_modes["eq"] = [(0, 1), (1, 0), (1, 1)]

  valid_ops = {(op,) + mode for op in ops for mode in valid_modes[op]}

  def get_operands(modes, operands, registers):
      result = []
      for mode, operand in zip(modes, operands):
          result.append(registers[operand] if mode else operand)
      return result
  split = 3298
  values = load(16, "int", footer=split)
  total = 0
  for state, operation, new_state in chunked(values, 3):
      count = 0
      operands = operation[1: -1]
      result = new_state[operation[-1]]
      for op, *mode in valid_ops:
          a, b = get_operands(mode, operands, state)
          if ops[op](a, b) == result:
              count += 1
      if count >= 3:
          total += 1
  total

#+end_src

** Part 2
With that out of the way, we can intersect all the potentially valid assignments for each test case, and use that to figure out which opcode corresponds to what. Running the program after that is fairly straightforward.
#+begin_src jupyter-python
  op_ids = defaultdict(lambda: valid_ops.copy())
  op_assignments = {}

  for state, operation, new_state in chunked(values, 3):
      op_number = operation[0]
      if op_number in op_assignments:
          continue
      operands = operation[1: -1]
      result = new_state[operation[-1]]
      candidate_ops = set()
      for op, *modes in valid_ops:
          a, b = get_operands(modes, operands, state)
          if ops[op](a, b) == result:
              candidate_ops.add((op,) + tuple(modes))
      op_ids[op_number] &= candidate_ops
      if len(op_ids[op_number]) ==  1:
          assignment = op_ids[op_number].pop()
          op_assignments[op_number] = assignment
          for i in range(16):
              op_ids[i].discard(assignment)
  state = [0, 0, 0, 0]
  program = load(16, "int", header=split)
  i = 0
  for op_id, a, b, c in program:
      op, *modes = op_assignments[op_id]
      a, b = get_operands(modes, (a, b), state)
      state[c] = ops[op](a, b)
  state[0]
#+end_src

* Day 18
[[https://adventofcode.com/2018/day/18][Settlers of The North Pole]]
** Part 1
#+begin_src jupyter-python
  state_map = {".": 0, "|": 1, "#": 2}
  reverse_map = {v: k for k, v in state_map.items()}
  state = np.array([[state_map[char] for char in line.strip()] for line in load(18)])
  weights = np.ones((3, 3))
  weights[1, 1] = 0
  seen = {}
  for i in range(10):
      seen[tuple(state.flatten())] = i
      tree_nb = scipy.ndimage.convolve(1 * (state == 1), weights, mode="constant")
      lumber_nb = scipy.ndimage.convolve(1 * (state == 2), weights, mode="constant")
      change = (((state == 0) & (tree_nb >= 3))
                | ((state == 1) & (lumber_nb >= 3))
                | ((state == 2) & ((tree_nb == 0) | (lumber_nb == 0))))
      state = (state + change) % 3
  (state == 1).sum() * (state == 2).sum()
#+end_src

** Part 2
There's no way we can run the simulation for that long. Hopefully we'll get a repeat before then
#+begin_src jupyter-python
  target = 1000000000
  for i in range(10, target):
      if tuple(state.flatten()) in seen:
          start = seen[tuple(state.flatten())]
          reversed_dict = {v: k for k, v in seen.items()}
          state = np.array(reversed_dict[start + (target - start) % (i - start)])
          break
      seen[tuple(state.flatten())] = i
      tree_nb = scipy.ndimage.convolve(1 * (state == 1), weights, mode="constant")
      lumber_nb = scipy.ndimage.convolve(1 * (state == 2), weights, mode="constant")
      change = (((state == 0) & (tree_nb >= 3))
                | ((state == 1) & (lumber_nb >= 3))
                | ((state == 2) & ((tree_nb == 0) | (lumber_nb == 0))))
      state = (state + change) % 3
  (state == 1).sum() * (state == 2).sum()

#+end_src

* Day 19
[[https://adventofcode.com/2018/day/19][Go With The Flow]]

** Part 1
#+begin_src jupyter-python
  basic_ops = ["add", "mul", "ban", "bor"]
  name_to_op = {
      basic_op + mode: (basic_op, 1, int(mode == "r"))
      for basic_op in basic_ops
      for mode in "ir"
  }

  name_to_op.update(**{"set" + mode: ("set", int(mode == "r"), 0) for mode in "ir"})
  name_to_op.update(
      ,**{
          comparison
          + mode_pair: (comparison, int(mode_pair[0] == "r"), int(mode_pair[1] == "r"))
          for comparison in ["gt", "eq"]
          for mode_pair in ["ir", "ri", "rr"]
      }
  )


  def interpret(op_name):
      name, *modes = name_to_op[op_name]
      return [ops[name], modes]


  def run(program, registers, ip_register):
      ip = 0
      while ip < len(program):
          registers[ip_register] = ip
          op, modes, a, b, c = program[ip]
          a, b = get_operands(modes, (a, b), registers)
          registers[c] = op(a, b)
          ip = registers[ip_register] + 1
      return registers[0]


  data = load(19)
  registers = [0, 0, 0, 0, 0, 0]
  ip, program = data[0], data[1:]
  ip_register = int(re.findall(r"-?\d+", ip)[0])
  program = [x.strip().split() for x in program]
  program = [interpret(line[0]) + [int(x) for x in line[1:]] for line in program]
  run(program, registers, ip_register)
#+end_src

** Part 2
This is another one of those where changing the value in the first register causes the code to go through a different path in the program, and greatly increases the runtime.

Analysing the execution path shows that the code starts off by jumping to a setup section at the end, which has the main effect of placing a value in register 5. It then jumps back to two nested loops, which go through a lot of busywork, and store their results in register 0. Finally, after a long time, it hits the exit condition of both loops, and the program ends.

Looking at the inner loop, it does the following

#+begin_src python
  for x4 in range(1, x5 + 1):
      if x4 * x2 == x5:
          x0 += x2
#+end_src

But thats equivalent to  ~x0 += x2 if x5 % x2 == 0 else 0~. The outer loop just runs over all values of x2 from 1 to x5. So what this code is really doing is calculating the sum of divisors function of whatever horrible mess is placed in x5 by the setup. We'll get that by running through the code until the setup is over, and then calculate the sum of divisors:

#+begin_src jupyter-python
  def sum_of_divisors(n):
      total = n + 1
      for i in range(2, n):
          if n % i == 0:
              total += i
      return total
  

  registers = [1, 0, 0, 0, 0, 0]
  ip = 0
  while ip != 1:
      registers[ip_register] = ip
      op, modes, a, b, c = program[ip]
      a, b = get_operands(modes, (a, b), registers)
      registers[c] = op(a, b)
      ip = registers[ip_register] + 1
  sum_of_divisors(registers[5])
#+end_src

* Day 20
[[https://adventofcode.com/2018/day/20][A Regular Map]]
** Part 1
The hard part of this problem is moving from the regex representation of the map to a more sensible one. A pseudo-ebnf of the grammar is:

path = direction, path | bracketed_path, path | options
direction = n|e|w|s
bracketed_path = (, path, )
options = (path, |)*, path?

Based on this, we can parse the string from start to finish by tracking a list of current positions. If a direction is encountered, each of the positions is updated. Whenever an opening bracket is encountered, the matching close bracket is found, the subexpression is split into options, and each of those paths is parsed. The visited edges are tracked along the way in a global dictionary. It's not super elegant, but it works.

#+begin_src jupyter-python
  s = load(20)[0].strip()[1:-1]
  directions = {"N": 1j, "E": 1, "S": -1j, "W": -1}
  def find_closing_paren(s):
      count = 0
      for idx, char in enumerate(s):
          count += 1 if char == "(" else -1 if char == ")" else 0
          if count == 0:
              return idx

  def split_into_options(s):
      count = 0
      result = []
      current = ""
      for char in s:
          if char == "|" and count == 0:
              result.append(current)
              current = ""
          else:
              current += char
          count += 1 if char == "(" else -1 if char == ")" else 0
      result.append(current)
      return result

  edges = defaultdict(bool)

  def endpoints(s, positions=None):
      i = 0
      if positions is None:
          positions = {0}
      else:
          positions = positions.copy()
      while i < len(s):
          char = s[i]
          if char == "(":
              delta = find_closing_paren(s[i:])
              substring = s[i+1: i+delta]
              options = split_into_options(substring)
              positions = {point for x in options for point in endpoints(x, positions)}
              i += delta
          else:
              direction = directions[char]
              positions = {x + direction for x in positions}
              for position in positions:
                  edges[2 * position - direction] = True
          i += 1
      return positions
  points = endpoints(s)

  def edge_to_nodes(x):
      return ((x.real - x.real % 2 + 1j * (x.imag - x.imag % 2)) / 2,
              (x.real + x.real % 2 + 1j * (x.imag + x.imag % 2)) / 2)

  nodes = len({node for edge in edges.keys() for node in edge_to_nodes(edge)})
#+end_src

With all that out of the way, the furthest room can be found with a BFS:
#+begin_src jupyter-python
  def neighbors(state):
      return [
          state + direction for direction in directions.values() if edges[2 * state + direction]
      ]

  utils.bfs(0, None, neighbors)
#+end_src

** Part 2

And finding how many rooms require at least 1000 steps can be found with the same BFS, but ending whenever we get a cost greater than 1000
#+begin_src jupyter-python
  end_condition = lambda cost, state: cost >= 1000
  nodes - len(utils.bfs(0, end_condition, neighbors, return_visited=True))
#+end_src

